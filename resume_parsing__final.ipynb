{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resume_parsing _final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i98LIZgp8mUF",
        "outputId": "923604fb-d004-4789-8e09-a391cd61b0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.7/dist-packages (0.8)\n",
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.7/dist-packages (1.27.12)\n",
            "Requirement already satisfied: pyresparser in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: preshed>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.0.6)\n",
            "Requirement already satisfied: pycryptodome>=3.8.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.14.1)\n",
            "Requirement already satisfied: nltk>=3.4.3 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.7)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (4.3.3)\n",
            "Requirement already satisfied: certifi>=2019.6.16 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.8.2)\n",
            "Requirement already satisfied: docx2txt>=0.7 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.8)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.25.11)\n",
            "Requirement already satisfied: spacy>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.2.4)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (21.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.23.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.10)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.15.0)\n",
            "Requirement already satisfied: srsly>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.0.5)\n",
            "Requirement already satisfied: cymem>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.0.6)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (4.64.0)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.0.4)\n",
            "Requirement already satisfied: pyrsistent>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.18.1)\n",
            "Requirement already satisfied: blis>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.4.1)\n",
            "Requirement already satisfied: pytz>=2019.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2022.1)\n",
            "Requirement already satisfied: pdfminer.six>=20181108 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (20220506)\n",
            "Requirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.4.0)\n",
            "Requirement already satisfied: thinc>=7.0.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (7.4.0)\n",
            "Requirement already satisfied: wasabi>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.9.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (4.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (5.7.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->pyresparser) (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (2022.4.24)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six>=20181108->pyresparser) (2.0.12)\n",
            "Requirement already satisfied: cryptography~=36.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six>=20181108->pyresparser) (36.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography~=36.0.0->pdfminer.six>=20181108->pyresparser) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography~=36.0.0->pdfminer.six>=20181108->pyresparser) (2.21)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from preshed>=2.0.1->pyresparser) (1.0.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (57.4.0)\n",
            "Requirement already satisfied: Document in /usr/local/lib/python3.7/dist-packages (1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.25.11)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.7/dist-packages (20220506)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (2.0.12)\n",
            "Requirement already satisfied: cryptography~=36.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (36.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography~=36.0.0->pdfminer.six) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography~=36.0.0->pdfminer.six) (2.21)\n",
            "Requirement already satisfied: docx in /usr/local/lib/python3.7/dist-packages (0.2.4)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.7/dist-packages (from docx) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from docx) (4.2.6)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.7/dist-packages (0.8.11)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.2.6)\n",
            "Requirement already satisfied: pyresparser in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: certifi>=2019.6.16 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.25.11)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.10)\n",
            "Requirement already satisfied: preshed>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.0.6)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (21.4.0)\n",
            "Requirement already satisfied: wasabi>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.9.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.23.0)\n",
            "Requirement already satisfied: nltk>=3.4.3 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.7)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.21.6)\n",
            "Requirement already satisfied: thinc>=7.0.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (7.4.0)\n",
            "Requirement already satisfied: pytz>=2019.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2022.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.15.0)\n",
            "Requirement already satisfied: docx2txt>=0.7 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.8)\n",
            "Requirement already satisfied: cymem>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.0.6)\n",
            "Requirement already satisfied: spacy>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.2.4)\n",
            "Requirement already satisfied: pycryptodome>=3.8.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.14.1)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (4.64.0)\n",
            "Requirement already satisfied: pdfminer.six>=20181108 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (20220506)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (3.0.4)\n",
            "Requirement already satisfied: blis>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.4.1)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (4.3.3)\n",
            "Requirement already satisfied: srsly>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (1.0.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (2.4.0)\n",
            "Requirement already satisfied: pyrsistent>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from pyresparser) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->pyresparser) (4.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.1->pyresparser) (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (2022.4.24)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.4.3->pyresparser) (7.1.2)\n",
            "Requirement already satisfied: cryptography~=36.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six>=20181108->pyresparser) (36.0.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six>=20181108->pyresparser) (2.0.12)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography~=36.0.0->pdfminer.six>=20181108->pyresparser) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography~=36.0.0->pdfminer.six>=20181108->pyresparser) (2.21)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from preshed>=2.0.1->pyresparser) (1.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.4->pyresparser) (1.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "!pip install docx2txt\n",
        "!pip install pypdf2\n",
        "!pip install pyresparser\n",
        "!pip install Document\n",
        "!pip install requests\n",
        "!pip install pdfminer.six\n",
        "!pip install docx\n",
        "!pip install python-docx\n",
        "!pip install pyresparser\n",
        "from docx import Document\n",
        "import docx2txt\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download(['stopwords','wordnet'])\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "from PyPDF2 import PdfFileReader, PdfFileWriter, PdfFileMerger\n",
        "\n",
        "#Extracting text from DOCX\n",
        "def doctotext(m):\n",
        "    temp = docx2txt.process(m)\n",
        "    resume_text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
        "    text = ' '.join(resume_text)\n",
        "    return (text)\n",
        "\n",
        "\n",
        "## Extracting text from PDF\n",
        "def pdftotext(m):\n",
        "    # pdf file object\n",
        "    # you can find find the pdf file with complete code in below\n",
        "    pdfFileObj = open(m, 'rb')\n",
        "\n",
        "    # pdf reader object\n",
        "    pdfFileReader = PdfFileReader(pdfFileObj)\n",
        "\n",
        "    # number of pages in pdf\n",
        "    num_pages = pdfFileReader.numPages\n",
        "\n",
        "    currentPageNumber = 0\n",
        "    text = ''\n",
        "\n",
        "    # Loop in all the pdf pages.\n",
        "    while(currentPageNumber < num_pages ):\n",
        "\n",
        "        # Get the specified pdf page object.\n",
        "        pdfPage = pdfFileReader.getPage(currentPageNumber)\n",
        "\n",
        "        # Get pdf page text.\n",
        "        text = text + pdfPage.extractText()\n",
        "\n",
        "        # Process next page.\n",
        "        currentPageNumber += 1\n",
        "    return (text)\n",
        "  \n",
        "if __name__ == '__main__': \n",
        "\n",
        "    FilePath = '/content/drive/MyDrive/Updated_Resume_Sailesh.pdf'\n",
        "    FilePath.lower().endswith(('.png', '.docx'))\n",
        "    if FilePath.endswith('.docx'):\n",
        "      textinput = doctotext(FilePath) \n",
        "    elif FilePath.endswith('.pdf'):\n",
        "      textinput = pdftotext(FilePath)\n",
        "    else:\n",
        "      print(\"File not support\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        " \n",
        " \n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        "\n",
        "\n",
        "\n",
        "def doctotext(m):\n",
        "    temp = docx2txt.process(m)\n",
        "    resume_text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
        "    text = ' '.join(resume_text)\n",
        "    return (text)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  FilePath = FilePath#'/content/drive/MyDrive/Ajinkya_Pathak_Resume.pdf.pdf'\n",
        "\n",
        "  #print(extract_text_from_pdf('/content/drive/MyDrive/Updated_Resume_Sailesh.pdf'))  # noqa: T001\n",
        "  pdfinput=extract_text_from_pdf(FilePath)\n",
        "\n",
        "\n",
        "  if FilePath.endswith('.docx'):\n",
        "      textinput = doctotext(FilePath) \n",
        "  elif FilePath.endswith('.pdf'):\n",
        "      textinput = extract_text_from_pdf(FilePath)\n",
        "\n",
        "else:\n",
        "  print(\"file not supported\")\n",
        "\n",
        "\n",
        "###########################################################################################################\n",
        "\n",
        "#Preprocessing of text data cleaning text data\n",
        "\n",
        "textinput=textinput.lower()\n",
        "textinput=textinput.split()\n",
        "\n",
        "clean_textinput = []\n",
        "\n",
        "lm = WordNetLemmatizer()\n",
        "textinput = [\n",
        "        lm.lemmatize(word)\n",
        "        for word in textinput\n",
        "        if not word in set(stopwords.words(\"english\"))\n",
        "    ]\n",
        "textinput = \" \".join(textinput)\n",
        "clean_textinput.append(textinput)\n",
        "clean_textinput=\"\".join(textinput)\n",
        "\n",
        "#############################################################################################\n",
        "#Code for Exrating Person's Name\n",
        "\n",
        "from spacy.util import validate_schema\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# initialize matcher with a vocab\n",
        "matcher = Matcher(nlp.vocab,validate=True)\n",
        "\n",
        "def extract_name(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "    \n",
        "    # First name and Last name are always Proper Nouns\n",
        "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "    \n",
        "    matcher.add('NAME', None,pattern)\n",
        "    \n",
        "    matches = matcher(nlp_text)\n",
        "    \n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        return span.text\n",
        "\n",
        "names=extract_name(clean_textinput)\n",
        "#print(names)\n",
        "\n",
        "###############################################################################################################################\n",
        "#Code for extracting Email id\n",
        "\n",
        "import re\n",
        " \n",
        "from pdfminer.high_level import extract_text\n",
        " \n",
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        " \n",
        "def extract_emails(resume_text):\n",
        "    return re.findall(EMAIL_REG, resume_text)\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    emails = extract_emails(clean_textinput)\n",
        " \n",
        "    #if emails:\n",
        "      #print(emails)  # noqa: T001\n",
        "\n",
        "#######################################################################################\n",
        "#Code for extracting Phone number\n",
        "\n",
        "#import re\n",
        "import subprocess  # noqa: S404\n",
        " \n",
        "PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
        "\n",
        "def extract_phone_number(resume_text):\n",
        "    phone = re.findall(PHONE_REG, resume_text)\n",
        " \n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        " \n",
        "        if resume_text.find(number) and len(number):\n",
        "            return number\n",
        "    return None\n",
        "\n",
        "if __name__ == '__main__':\n",
        "   phone_number = extract_phone_number(clean_textinput)\n",
        "   #print(phone_number)\n",
        "\n",
        "\n",
        "#####################################################################################################\n",
        "#code for extracting Skills\n",
        "\n",
        "from pyresparser import ResumeParser\n",
        "import os \n",
        "\n",
        "##file format should be in .txt , .docx or .pdf only\n",
        "#filed='/content/drive/MyDrive/Updated_Resume_Sailesh.pdf'\n",
        "\n",
        "try:\n",
        "    doc = Document()\n",
        "    with open(FilePath, 'r') as file:\n",
        "        doc.add_paragraph(file.read())\n",
        "    doc.save(\"text.docx\")\n",
        "    data = ResumeParser('text.docx').get_extracted_data()\n",
        "    print(data['skills'])\n",
        "    print(data['degree'])\n",
        "    \n",
        "except:\n",
        "    data = ResumeParser(FilePath).get_extracted_data()\n",
        "    #print(data['skills'])\n",
        "\n",
        "\n",
        "#################################################################################################################\n",
        "#Code for extracting Linkedin links\n",
        "\n",
        "import re\n",
        " \n",
        "from pdfminer.high_level import extract_text\n",
        " \n",
        "Linkedin = re.compile(r'linkedin\\.com\\/in\\/\\w+\\-\\w+\\-\\w+')\n",
        "#Linkedin = re.compile(r'https\\:\\/\\/w+\\.linkedin\\.com\\/in\\/\\w+\\-\\w+\\/')\n",
        " \n",
        "def linkedin_links(resume_text):\n",
        "    return re.findall(Linkedin, resume_text)\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    linkedin = linkedin_links(clean_textinput)\n",
        " \n",
        "    #if linkedin:\n",
        "        #print(linkedin)  # noqa: T001\n",
        "\n",
        "\n",
        "#############################################################################################################\n",
        "#Code for extracting Github Links\n",
        "\n",
        "import re\n",
        " \n",
        "from pdfminer.high_level import extract_text\n",
        " \n",
        "Github = re.compile(r'https:\\/\\/github.com\\/\\w+')\n",
        " \n",
        "def github_links(resume_text):\n",
        "    return re.findall(Github, resume_text)\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    github = github_links(clean_textinput)\n",
        " \n",
        "    #if github:\n",
        "        #print(github)  # noqa: T001\n",
        "\n",
        "###############################################################################################################\n",
        "#Extracting Education details\n",
        "def convert_file_to_list(file):\n",
        "    file = open(file)\n",
        "    file = file.readlines()\n",
        "    lines = []\n",
        "    lines=[line.strip() for line in file]\n",
        "    return lines\n",
        "\n",
        "\n",
        "def extract_education(resume_text):\n",
        "    organizations = []\n",
        "    for sent in nltk.sent_tokenize(resume_text):\n",
        "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "            if hasattr(chunk, 'label') and chunk.label() == 'ORGANIZATION':\n",
        "                organizations.append(' '.join(c[0] for c in chunk.leaves()))\n",
        "    education = set()\n",
        "    education_db = convert_file_to_list(\"/content/drive/MyDrive/schools.txt\")\n",
        "    for org in organizations:\n",
        "        for word in education_db:\n",
        "            if org.lower().find(word) >= 0:\n",
        "                education.add(org)\n",
        "    return education\n",
        "\n",
        "education = extract_education(pdfinput)\n",
        "#print(education)\n",
        "\n",
        "#################################################################################################################\n",
        "#Extracting skills\n",
        "\n",
        "try:\n",
        "    doc = Document()\n",
        "    with open(FilePath, 'r') as file:\n",
        "        doc.add_paragraph(file.read())\n",
        "    doc.save(\"text.docx\")\n",
        "    data = ResumeParser('text.docx').get_extracted_data()\n",
        "    #print(data['email'])\n",
        "    #print(data['degree'])\n",
        "    \n",
        "except:\n",
        "    data = ResumeParser(FilePath).get_extracted_data()\n",
        "    #print(data['skills'])\n",
        "    #print(data['degree'])\n",
        "    #print(data['experience'])\n",
        "    #print(data['company_names'])\n",
        "    #print(data['total_experience'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "details=[]\n",
        "\n",
        "#print(names)\n",
        "#print(phone_number)\n",
        "#print(emails)\n",
        "#print(github)\n",
        "#print(linkedin)\n",
        "#print(data['skills'])\n",
        "#print(education)\n",
        "#print(data['degree'])\n",
        "#print(data['experience'])\n",
        "#print(data['company_names'])\n",
        "#print(data['total_experience'])\n",
        "\n",
        "details.append(names)\n",
        "details.append(phone_number)\n",
        "details.append(emails)\n",
        "details.append(github)\n",
        "details.append(linkedin)\n",
        "details.append(data['skills'])\n",
        "details.extend(education)\n",
        "details.append(data['degree'])\n",
        "details.append(data['experience'])\n",
        "details.append(data['company_names'])\n",
        "details.append(data['total_experience'])\n",
        "\n",
        "#details\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "json_string = json.dumps(details,indent=10)\n",
        "print(json_string)\n"
      ],
      "metadata": {
        "id": "9bk-8DtuFtL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a190f616-363c-45c8-f7b9-78e006bc010b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "          \"sailesh tirumala\",\n",
            "          \"+1 (807)-357-9767\",\n",
            "          [\n",
            "                    \"sailesh.tirumala@gmail.com\"\n",
            "          ],\n",
            "          [\n",
            "                    \"https://github.com/saileshtirumala\"\n",
            "          ],\n",
            "          [\n",
            "                    \"linkedin.com/in/sailesh-tirumala-8aa015185\"\n",
            "          ],\n",
            "          [\n",
            "                    \"Github\",\n",
            "                    \"Mobile\",\n",
            "                    \"Design\",\n",
            "                    \"Keras\",\n",
            "                    \"Algorithms\",\n",
            "                    \"Opencv\",\n",
            "                    \"Sql\",\n",
            "                    \"Aws\",\n",
            "                    \"Datasets\",\n",
            "                    \"C\",\n",
            "                    \"Php\",\n",
            "                    \"Twitter\",\n",
            "                    \"Computer science\",\n",
            "                    \"System\",\n",
            "                    \"Wtforms\",\n",
            "                    \"Research\",\n",
            "                    \"Docker\",\n",
            "                    \"Health\",\n",
            "                    \"Flask\",\n",
            "                    \"Html\",\n",
            "                    \"Javascript\",\n",
            "                    \"Machine learning\",\n",
            "                    \"Ai\",\n",
            "                    \"Cloud\",\n",
            "                    \"Testing\",\n",
            "                    \"R\",\n",
            "                    \"Xgboost\",\n",
            "                    \"Pandas\",\n",
            "                    \"Programming\",\n",
            "                    \"Database\",\n",
            "                    \"Tableau\",\n",
            "                    \"Numpy\",\n",
            "                    \"Analysis\",\n",
            "                    \"Java\",\n",
            "                    \"Nltk\",\n",
            "                    \"Api\",\n",
            "                    \"Email\",\n",
            "                    \"Python\",\n",
            "                    \"Tensorflow\",\n",
            "                    \"Ui\",\n",
            "                    \"Sci\",\n",
            "                    \"Analytics\",\n",
            "                    \"Technical\",\n",
            "                    \"Css\",\n",
            "                    \"Operations\"\n",
            "          ],\n",
            "          \"GITAM University\",\n",
            "          \"Lakehead University\",\n",
            "          \"Computer Science Lakehead University\",\n",
            "          [\n",
            "                    \"Bachelor of Technology, Computer Science                                                          July 2015- May 2019 \\nGITAM University\",\n",
            "                    \"Master of Science, Computer Science\"\n",
            "          ],\n",
            "          [],\n",
            "          null,\n",
            "          0.0\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lWGOxm-12J4J"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_0CRPXcHElYY"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4SpnNHvyqgeL"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TwjWvMzYFNdo"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6TM-4ttHWLAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}